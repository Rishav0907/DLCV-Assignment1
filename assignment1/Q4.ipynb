{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "009acc78-3efa-43e5-a6e1-7e69ee3ca58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# ## Define a class Convolution Layer, which is initialized with the various required params:\n",
    "# class Convolution_Layer():\n",
    "    \n",
    "#     def __init__(self,input_image , filter_size, bias=True, stride=1, padding=0, dilation=1):\n",
    "#         # For an untrained layer, set random initial filter weights\n",
    "#         self.input_image=input_image\n",
    "#         self.filter_size=filter_size\n",
    "#         self.bias=True\n",
    "#         self.stride=stride\n",
    "#         self.padding=padding\n",
    "#         self.dilation=dilation\n",
    "#         self.input_channel=3\n",
    "        \n",
    "#         #setting random filter weights\n",
    "#         self.filter_weights=np.random.rand(self.filter_size,self.filter_size)\n",
    "#         # print(self.filter_weights)\n",
    "#     def forward(self,input_image):\n",
    "#         # Input Proprocess(According to pad etc.) Input will be of size (Batch_size, in_channels, inp_height, inp_width)\n",
    "#         batch_size=input_image.shape[0]\n",
    "#         input_size=input_image.shape[1]\n",
    "#         #reshaping the image into 10000*3*32*32\n",
    "#         input_image=input_image.reshape((batch_size,self.input_channel,32,32))\n",
    "        \n",
    "#         out_height = (32 + 2 * self.padding - self.dilation * (self.filter_size - 1) - 1) // self.stride + 1\n",
    "#         out_width = (32 + 2 * self.padding - self.dilation * (self.filter_size - 1) - 1) // self.stride + 1\n",
    "        \n",
    "#         #creating the output image matrix\n",
    "#         output = np.zeros((batch_size, self.input_channel, out_height, out_width))\n",
    "#         # print(out_height)\n",
    "#         # Reminder: Save Input for backward-prop\n",
    "#         # Simple Conv operation:\n",
    "#         # Loop over every location in inp_height * inp_width for the whole batch\n",
    "#         print(input_image)\n",
    "#         for batch in range(batch_size):\n",
    "#             for channel in range(self.input_channel):\n",
    "#                 for height in  range(out_height):\n",
    "#                     for width in range(out_width):\n",
    "#                         current_image_part=input_image[batch,channel,height*self.stride:height*self.stride+self.filter_size,width*self.stride:width*self.stride+self.filter_size]\n",
    "#                         output[batch, channel, height, width] = np.sum(current_image_part * self.filter_weights[channel]) + (self.bias[channel] if self.bias is not None else 0)\n",
    "        \n",
    "    \n",
    "#         # Output will be of the size (Batch_size, out_channels, out_height, out_width)\n",
    "#         return output\n",
    "    \n",
    "#     def backward(self, grad_of_output_size):\n",
    "        \n",
    "#         # Naive Implementation\n",
    "#         # Speed is not a concern\n",
    "#         # Hint: gradients from each independant operation can be summed\n",
    "        \n",
    "#         #  return gradient of the size of the weight kernel\n",
    "#         return grad\n",
    "    \n",
    "#     def set_weights(self, new_weights):\n",
    "#         ## Replace the set of weights with the given 'new_weights'\n",
    "#         ## use this for setting weights for blurring, bilateral filtering etc. \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a66d9b-4351-4450-befc-098242ba26e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "class Convolution_Layer():\n",
    "    \n",
    "    def __init__(self, filter_size, bias=True, stride=1, padding=0, dilation=1):\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.bias = bias\n",
    "        self.input_channel=3\n",
    "        # Initialize filter weights randomly\n",
    "        self.weights = np.random.randn(filter_size, filter_size)\n",
    "        # self.batch_size=input_image.shape[0]\n",
    "        # If bias is True, initialize bias terms\n",
    "        if bias:\n",
    "            self.bias = np.random.randn(1)\n",
    "        else:\n",
    "            self.bias = None\n",
    "    # @njit\n",
    "    def forward(self, input_image):\n",
    "        input_image=input_image.reshape((10000,self.input_channel,32,32))\n",
    "        batch_size, in_channels, inp_height, inp_width = input_image.shape\n",
    "        out_channels = self.weights.shape[0]\n",
    "        \n",
    "        # Calculate output dimensions\n",
    "        out_height = int(((inp_height + 2*self.padding - self.dilation*(self.filter_size - 1) - 1) / self.stride) + 1)\n",
    "        out_width = int(((inp_width + 2*self.padding - self.dilation*(self.filter_size - 1) - 1) / self.stride) + 1)\n",
    "        \n",
    "        # Padding input image\n",
    "        padded_input = np.pad(input_image, ((0,0), (0,0), (self.padding,self.padding), (self.padding,self.padding)), mode='constant')\n",
    "        \n",
    "        # Initialize output\n",
    "        output = np.zeros((batch_size, out_channels, out_height, out_width))\n",
    "        \n",
    "        # Convolution\n",
    "        for b in range(batch_size):\n",
    "            for c_out in range(out_channels):\n",
    "                for h_out in range(out_height):\n",
    "                    for w_out in range(out_width):\n",
    "                        h_start = h_out * self.stride\n",
    "                        h_end = h_start + self.filter_size * self.dilation\n",
    "                        w_start = w_out * self.stride\n",
    "                        w_end = w_start + self.filter_size * self.dilation\n",
    "                        \n",
    "                        receptive_field = padded_input[b, :, h_start:h_end:self.dilation, w_start:w_end:self.dilation]\n",
    "                        output[b, c_out, h_out, w_out] = np.sum(receptive_field * self.weights[c_out]) + self.bias\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_of_output_size):\n",
    "        batch_size, out_channels, out_height, out_width = grad_of_output_size.shape\n",
    "        _, in_channels, inp_height, inp_width = self.input_shape\n",
    "        \n",
    "        # Initialize gradients\n",
    "        grad_weights = np.zeros_like(self.weights)\n",
    "        grad_bias = np.zeros_like(self.bias)\n",
    "        grad_input = np.zeros(self.input_shape)\n",
    "        \n",
    "        # Compute gradients\n",
    "        for b in range(batch_size):\n",
    "            for c_out in range(out_channels):\n",
    "                for h_out in range(out_height):\n",
    "                    for w_out in range(out_width):\n",
    "                        h_start = h_out * self.stride\n",
    "                        h_end = h_start + self.filter_size * self.dilation\n",
    "                        w_start = w_out * self.stride\n",
    "                        w_end = w_start + self.filter_size * self.dilation\n",
    "                        \n",
    "                        receptive_field = self.input_image[b, :, h_start:h_end:self.dilation, w_start:w_end:self.dilation]\n",
    "                        \n",
    "                        grad_weights[c_out] += grad_of_output_size[b, c_out, h_out, w_out] * receptive_field\n",
    "                        grad_bias += grad_of_output_size[b, c_out, h_out, w_out]\n",
    "                        grad_input[b, :, h_start:h_end:self.dilation, w_start:w_end:self.dilation] += grad_of_output_size[b, c_out, h_out, w_out] * self.weights[c_out]\n",
    "        \n",
    "        return grad_input, grad_weights, grad_bias\n",
    "    \n",
    "    def set_weights(self, new_weights):\n",
    "        self.weights = new_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435ed102-86d3-45b8-9880-12d53661fb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sol=Convolution_Layer(filter_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeccd9e2-3e5e-4cdf-8436-da88517c0cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_CIFAR():\n",
    "    file_path='cifar-10-batches-py\\data_batch_1'\n",
    "    with open(file_path,'rb') as file:\n",
    "        data=pickle.load(file,encoding='bytes')\n",
    "    # for key in data.keys():\n",
    "        # print(key)\n",
    "    image_data=data[b'data']\n",
    "    return image_data\n",
    "input_data=load_CIFAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de076d2-0cd2-4365-850f-80440a6cbfce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de27b68-c9c0-477d-99eb-c1e6c576f8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 15360 into shape (10000,3,32,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m res\u001b[38;5;241m=\u001b[39msol\u001b[38;5;241m.\u001b[39mforward(input_data[:\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m, in \u001b[0;36mConvolution_Layer.forward\u001b[1;34m(self, input_image)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_image):\n\u001b[1;32m---> 22\u001b[0m     input_image\u001b[38;5;241m=\u001b[39minput_image\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m10000\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channel,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m     23\u001b[0m     batch_size, in_channels, inp_height, inp_width \u001b[38;5;241m=\u001b[39m input_image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     24\u001b[0m     out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 15360 into shape (10000,3,32,32)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "res=sol.forward(input_data[:5])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8b0c-5ad5-4929-9964-efcf7e5d53ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de39c085-61b7-4c35-8fa3-c68223519198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class Convolution_Layer():\n",
    "    \n",
    "#     def __init__(self, input_data, filter_size, bias=True, stride=1, padding=0, dilation=1):\n",
    "#         self.input_channels = input.shape[1]\n",
    "#         self.filter_size = filter_size\n",
    "#         self.bias = bias\n",
    "#         self.stride = stride\n",
    "#         self.padding = padding\n",
    "#         self.dilation = dilation\n",
    "        \n",
    "#         # Initialize filter weights with random values\n",
    "#         self.weights = np.random.randn(self.input_channels, filter_size, filter_size)\n",
    "        \n",
    "#         # Initialize bias if needed\n",
    "#         if bias:\n",
    "#             self.bias = np.zeros((self.input_channels,))\n",
    "#         else:\n",
    "#             self.bias = None\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         batch_size, in_channels, in_height, in_width = input.shape\n",
    "#         out_height = (in_height + 2 * self.padding - self.dilation * (self.filter_size - 1) - 1) // self.stride + 1\n",
    "#         out_width = (in_width + 2 * self.padding - self.dilation * (self.filter_size - 1) - 1) // self.stride + 1\n",
    "        \n",
    "#         # Apply padding to the input\n",
    "#         padded_input = np.pad(input, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
    "        \n",
    "#         output = np.zeros((batch_size, self.input_channels, out_height, out_width))\n",
    "        \n",
    "#         for b in range(batch_size):\n",
    "#             for ic in range(self.input_channels):\n",
    "#                 for oh in range(out_height):\n",
    "#                     for ow in range(out_width):\n",
    "#                         # Extract the current receptive field\n",
    "#                         receptive_field = padded_input[b, ic, oh*self.stride:oh*self.stride+self.filter_size, ow*self.stride:ow*self.stride+self.filter_size]\n",
    "#                         # Perform convolution\n",
    "#                         output[b, ic, oh, ow] = np.sum(receptive_field * self.weights[ic]) + (self.bias[ic] if self.bias is not None else 0)\n",
    "        \n",
    "#         return output\n",
    "    \n",
    "#     def backward(self, grad_of_output_size):\n",
    "#         batch_size, input_channels, out_height, out_width = grad_of_output_size.shape\n",
    "        \n",
    "#         grad_of_input = np.zeros_like(grad_of_output_size)\n",
    "#         grad_of_weights = np.zeros_like(self.weights)\n",
    "#         grad_of_bias = np.zeros_like(self.bias) if self.bias is not None else None\n",
    "        \n",
    "#         for b in range(batch_size):\n",
    "#             for ic in range(self.input_channels):\n",
    "#                 for oh in range(out_height):\n",
    "#                     for ow in range(out_width):\n",
    "#                         # Extract the current receptive field from the input\n",
    "#                         receptive_field = input[b, ic, oh*self.stride:oh*self.stride+self.filter_size, ow*self.stride:ow*self.stride+self.filter_size]\n",
    "#                         # Compute gradient of input\n",
    "#                         grad_of_input[b, ic, oh*self.stride:oh*self.stride+self.filter_size, ow*self.stride:ow*self.stride+self.filter_size] += self.weights[ic] * grad_of_output_size[b, ic, oh, ow]\n",
    "#                         # Compute gradient of weights\n",
    "#                         grad_of_weights[ic] += receptive_field * grad_of_output_size[b, ic, oh, ow]\n",
    "#                         # Compute gradient of bias\n",
    "#                         if self.bias is not None:\n",
    "#                             grad_of_bias[ic] += grad_of_output_size[b, ic, oh, ow]\n",
    "        \n",
    "#         return grad_of_input, grad_of_weights, grad_of_bias\n",
    "    \n",
    "#     def set_weights(self, new_weights):\n",
    "#         self.weights = new_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad114cb-e922-4ac8-8114-1e6e9d51a861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8231b394-847d-41f3-aa7f-193369bd967e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "801e0d4f-82e3-4455-a25c-c73149298740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "load_CIFAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c8bc3-ef99-496f-9995-ebbeb53bc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
